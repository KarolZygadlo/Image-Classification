\chapter{Implementacja}
\section{Budowa modelu sieci neuronowej}

W celu rozwiązania problemu rozpoznawania wad produkcyjnych, zastosowano sieć neuronową opartą na architekturze konwolucyjnej (CNN). Sieci tego typu są powszechnie używane w problemach analizy obrazów, ponieważ potrafią efektywnie wykrywać lokalne wzorce i cechy na obrazach. W tym przypadku, sieć będzie w stanie nauczyć się rozpoznawania różnych wad produkcyjnych na podstawie analizy dostarczonych zdjęć.

Model sieci neuronowej został zaimplementowany przy użyciu biblioteki TensorFlow w języku Python. Poniżej przedstawiono kod źródłowy użyty do budowy modelu:

\begin{verbatim}
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, 
MaxPooling2D, Dense, Flatten, Dropout

model = Sequential()

model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))
model.add(MaxPooling2D())

model.add(Conv2D(32, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Conv2D(16, (3,3), 1, activation='relu'))
model.add(MaxPooling2D())

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
\end{verbatim}

Sieć składa się z trzech warstw konwolucyjnych z funkcją aktywacji ReLU oraz warstwami MaxPooling po każdej z nich. Warstwy konwolucyjne uczą się wykrywać lokalne cechy na obrazach, a MaxPooling pomaga w redukcji wymiarowości, co przyspiesza uczenie i zmniejsza ryzyko przeuczenia.

Po trzech warstwach konwolucyjnych, sieć przechodzi przez warstwę Flatten, która spłaszcza dane do jednowymiarowego wektora, co pozwala na przekazanie ich do warstw gęstych (Dense). W tym przypadku, użyto jednej warstwy gęstej z 256 neuronami i funkcją aktywacji ReLU.

Na końcu, sieć kończy się warstwą gęstą z jednym neuronem i funkcją aktywacji sigmoidalną. Ta warstwa odpowiada za generowanie wyników klasyfikacji, gdzie wartość bliska 0 wskazuje na uszkodzony produkt, a wartość bliska 1 na prawidłowy.

Model został skompilowany z użyciem optymalizatora Adam, funkcji straty BinaryCrossentropy oraz metryki dokładności:

\begin{verbatim}
model.compile('adam', loss=tf.losses.BinaryCrossentropy(),
metrics=['accuracy'])
\end{verbatim}

Zastosowanie optymalizatora Adam pomaga w szybszym i skuteczniejszym uczeniu się sieci, gdyż dostosowuje szybkość uczenia na podstawie zmian gradientu. Funkcja straty BinaryCrossentropy jest odpowiednia do problemów klasyfikacji binarnej, takich jak ten, ponieważ pozwala na ocenę różnic między prawdziwymi etykietami a prognozowanymi przez sieć.

\section{Trenowanie modelu}

Trenowanie modelu sieci neuronowej to proces optymalizacji wag w sieci, aby osiągnąć jak najlepszą wydajność w rozpoznawaniu wad produkcyjnych na podstawie zdjęć. W implementacji wykorzystano dane treningowe i walidacyjne do uczenia modelu oraz oceny jego wydajności podczas trenowania. W tej sekcji omówione zostanie trenowanie modelu, analiza wydajności oraz sposób monitorowania procesu uczenia.

Wykorzystano metodę \verb|fit| dostarczoną przez bibliotekę Keras, aby przeszkolić model sieci neuronowej. Poniższy kod przedstawia sposób trenowania modelu przez 5 epok, używając danych treningowych oraz walidacyjnych:

\begin{verbatim}
hist = model.fit(train, epochs=5, 
validation_data=val, callbacks=[tensorboard_callback])
\end{verbatim}

Parametr \verb|epochs| określa liczbę pełnych przebiegów przez dane treningowe. W każdej epoce model próbuje zminimalizować funkcję straty na danych treningowych, dostosowując wagi sieci neuronowej. Użycie danych walidacyjnych pozwala na obserwację procesu uczenia się i wykrycie ewentualnego przeuczenia modelu. Jeśli model zaczyna się przeuczać, dokładność na danych walidacyjnych zacznie maleć, podczas gdy dokładność na danych treningowych nadal będzie rosnąć.

TensorBoard to narzędzie do wizualizacji uczenia sieci neuronowych, które pozwala na monitorowanie różnych metryk, takich jak funkcja straty i dokładność. W implementacji użyto TensorBoard jako wywołania zwrotnego podczas trenowania, co pozwala na automatyczne zapisywanie danych do logów:

\begin{verbatim}
logdir='logs'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)
\end{verbatim}

Logi TensorBoard można następnie wyświetlić w przeglądarce, aby uzyskać interaktywną wizualizację procesu uczenia. Aby uruchomić TensorBoard, należy wpisać w terminalu poniższe polecenie, a następnie otworzyć wyświetlony adres URL w przeglądarce:

\begin{verbatim}
tensorboard --logdir=logs
\end{verbatim}

Po zakończeniu trenowania modelu, można ocenić jego wydajność na podstawie historii uczenia. Poniższy kod przedstawia sposób tworzenia wykresów straty oraz dokładności dla danych treningowych i walidacyjnych:

\begin{verbatim}
fig = plt.figure()
plt.plot(hist.history['loss'], color='teal', 
label='strata treningowa')
plt.plot(hist.history['val_loss'], color='orange', 
label='strata walidacji')
fig.suptitle('Strata', fontsize=20)
plt.legend(loc="upper left")
plt.show()

fig = plt.figure()
plt.plot(hist.history['accuracy'], color='teal', 
label='dokładność treningowa')
plt.plot(hist.history['val_accuracy'], color='orange', 
label='dokładność walidacji')
fig.suptitle('Dokładność', fontsize=20)
plt.legend(loc="upper left")
plt.show()
\end{verbatim}

Wykresy te pozwalają na analizę wydajności modelu w czasie trenowania. Na wykresie straty obserwujemy spadek wartości funkcji straty zarówno dla danych treningowych, jak i walidacyjnych. Jeśli model jest odpowiednio uczone, strata na danych walidacyjnych powinna stabilizować się na niskim poziomie.

Wykres dokładności przedstawia, jak dobrze model radzi sobie z klasyfikacją próbek na danych treningowych i walidacyjnych. W miarę jak model się uczy, dokładność powinna rosnąć, aż osiągnie pewien poziom, po którym może wystąpić przeuczenie. W przypadku przeuczenia, dokładność na danych treningowych będzie nadal rosnąć, podczas gdy dokładność na danych walidacyjnych będzie maleć.

\section{Wczytywanie przykładowego obrazu}
W tym oraz w kolejnych podrozdziałach omówione zostanie testowanie modelu na przykładach obrazów, sprawdzając jego zdolność do klasyfikacji zdjęć jako uszkodzonych lub prawidłowych elementów. Testowanie modelu odbywa się na podstawie dostarczonego kodu źródłowego.
Pierwszym krokiem w testowaniu modelu jest wczytanie przykładowego obrazu, który zostanie następnie przekazany do modelu w celu klasyfikacji. Wczytujemy obraz za pomocą biblioteki OpenCV:

\begin{lstlisting}[language=Python]
img = cv2.imread('testing/failure_4.png')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()
\end{lstlisting}

\section{Przeskalowanie obrazu}
Przed przekazaniem obrazu do modelu, konieczne jest jego przeskalowanie do wymiarów, na których model został wytrenowany. W naszym przypadku, model został przeszkolony na obrazach o wymiarach 256x256 pikseli. Przeskalowanie obrazu odbywa się za pomocą funkcji \texttt{tf.image.resize}:

\begin{lstlisting}[language=Python]
resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()
\end{lstlisting}

\section{Predykcja klasy obrazu}
Następnie przekazujemy przeskalowany obraz do modelu, aby uzyskać predykcję klasy. Przed przekazaniem obrazu do modelu, konieczne jest jego normalizowanie przez podzielenie wartości pikseli przez 255:

\begin{lstlisting}[language=Python]
yhat = model.predict(np.expand_dims(resize/255, 0))
\end{lstlisting}

\section{Interpretacja wyników}
Wynik predykcji (\texttt{yhat}) to wartość od 0 do 1, która wskazuje na przynależność obrazu do klasy 'prawidłowy'. Aby uzyskać konkretną klasę obrazu, ustalamy próg (np. 0,5) i sprawdzamy, czy wartość predykcji przekracza ten próg:

\begin{lstlisting}[language=Python]
if yhat > 0.5:
print(f'Wskazany obraz zostal sklasyfikowany jako czesc prawidlowa')
else:
print(f'Wskazany obraz zostal sklasyfikowany jako czesc uszkodzona')
\end{lstlisting}

W ten sposób możemy przetestować model na różnych przykładach obrazów i ocenić jego zdolność do klasyfikacji uszkodzonych i prawidłowych elementów. Testowanie modelu na przykładach jest istotne dla praktycznego zastosowania modelu w rzeczywistych scenariuszach, gdzie musi on poprawnie klasyfikować różnorodne obrazy przedstawiające uszkodzone i prawidłowe elementy.

\section{Zapisywanie modelu}
Aby zachować wytrenowany model i umożliwić jego dalsze wykorzystanie, należy zapisać jego strukturę i parametry. Dzięki temu będziemy mogli wczytać model i użyć go do klasyfikacji obrazów w przyszłości bez konieczności przeprowadzania procesu treningowego ponownie.
Zapisanie modelu w TensorFlow odbywa się za pomocą metody \texttt{save}:

\begin{lstlisting}[language=Python]
model.save(os.path.join('models', 'imageclassicationversionlive.h5'))
\end{lstlisting}

Model zostaje zapisany w formacie HDF5, który przechowuje zarówno architekturę modelu, jak i nauczone wagi.

\section{Wczytywanie modelu}
Aby wczytać zapisany model, używamy funkcji \texttt{load\_model} z biblioteki TensorFlow:

\begin{lstlisting}[language=Python]
new_model = load_model(os.path.join('models', 'imageclassicationversionlive.h5'))
\end{lstlisting}

Wczytany model można następnie wykorzystać do przewidywania klasy obrazów, podobnie jak przed zapisaniem:

\begin{lstlisting}[language=Python]
img = cv2.imread('testing/failure_4.png')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()
resize = tf.image.resize(img, (256,256))
plt.imshow(resize.numpy().astype(int))
plt.show()

yhat = model.predict(np.expand_dims(resize/255, 0))
if yhat > 0.5:
print(f'Wskazany obraz zostal sklasyfikowany jako czesc prawidlowa')
else:
print(f'Wskazany obraz zostal sklasyfikowany jako czesc uszkodzona')
\end{lstlisting}

Dzięki zapisywaniu i wczytywaniu modelu mamy możliwość przechowywania i wykorzystywania wyników treningu w dowolnym momencie, co pozwala na efektywniejsze wykorzystanie zasobów obliczeniowych oraz sprawne wdrażanie modeli do praktycznych zastosowań.