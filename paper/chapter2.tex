\chapter{Wybrane podstawy teoretyczne pracy}

\section{Uczenie głębokie}
Uczenie głębokie to gałąź uczenia maszynowego, która skupia się na zastosowaniu sztucznych sieci neuronowych z wieloma warstwami ukrytymi. W przeciwieństwie do tradycyjnych metod uczenia maszynowego, takich jak regresja liniowa czy drzewa decyzyjne, uczenie głębokie automatycznie odkrywa reprezentacje danych na różnych poziomach abstrakcji. Jest to kluczowe dla rozwiązywania złożonych problemów, takich jak rozpoznawanie obrazów, przetwarzanie języka naturalnego, rozpoznawanie mowy czy analiza danych biologicznych. 
Uczenie głębokie to specjalna odmiana uczenia maszynowego, w ramach której sztuczne sieci neuronowe, czyli algorytmy stworzone tak, aby naśladować sposób działania ludzkiego mózgu, uczą się na podstawie obszernych zbiorów danych. Uczenie głębokie opiera się na wielowarstwowych sieciach neuronowych, które są algorytmami wzorowanymi na sposób funkcjonowania ludzkich mózgów. Szkolenie z dużą ilością danych kształtuje neurony w sieci neuronowej, co prowadzi do stworzenia modelu uczenia głębokiego zdolnego do przetwarzania nowych danych po przeszkoleniu. Modele uczenia głębokiego korzystają z informacji z różnych źródeł danych i analizują je w czasie rzeczywistym, bez potrzeby ingerencji człowieka. W procesie uczenia głębokiego, procesory graficzne (GPU) są optymalizowane do pracy z modelami szkoleniowymi, ponieważ mogą równocześnie wykonywać wiele obliczeń.
Uczenie głębokie jest siłą napędową wielu technologii sztucznej inteligencji (AI), które mogą zautomatyzować i usprawnić zadania analityczne. Większość osób codziennie styka się z uczeniem głębokim, przeglądając internet czy korzystając z telefonów komórkowych. Wśród licznych zastosowań, uczenie głębokie jest wykorzystywane do generowania napisów dla filmów na YouTube, rozpoznawania mowy w telefonach i inteligentnych głośnikach, identyfikowania twarzy na zdjęciach czy tworzenia autonomicznych pojazdów. W miarę jak analitycy i badacze danych podejmują coraz bardziej zaawansowane projekty związane z uczeniem głębokim, wykorzystując architektury głębokich sieci neuronowych, ten rodzaj sztucznej inteligencji stanie się jeszcze bardziej powszechny w naszym codziennym życiu.


\subsection{Historia uczenia głębokiego}
Historia uczenia głębokiego sięga lat 40. XX wieku, kiedy to badacze zaczęli eksplorować koncepcje sztucznych neuronów, które próbowały naśladować biologiczne procesy zachodzące w ludzkim mózgu. W 1986 roku Rumelhart, Hinton i Williams wprowadzili algorytm wstecznej propagacji błędów (backpropagation), który umożliwił efektywne uczenie się sieci neuronowych.
\paragraph{}
W 2006 roku Hinton i Salakhutdinov opublikowali pracę, która przyczyniła się do powstania współczesnego uczenia głębokiego. Przedstawili w niej skonstruowane przez siebie głębokie sieci wstępnie uczące się (deep belief networks) i pokazali, że sieci te potrafią uczyć się reprezentacji danych na wielu poziomach abstrakcji. Od tego czasu uczenie głębokie zyskało na popularności, a rozwój technologii przyczynił się do udoskonalenia algorytmów oraz wykorzystania uczenia głębokiego w praktyce.

\subsection{Zastosowania uczenia głębokiego}
Uczenie głębokie znalazło szerokie zastosowanie w różnych dziedzinach nauki i przemysłu. Przykłady obejmują:
\begin{itemize}
\item Rozpoznawanie obrazów: wykorzystanie sieci konwolucyjnych (CNN) do klasyfikacji obrazów, detekcji obiektów czy segmentacji obrazów.
\item Przetwarzanie języka naturalnego: stosowanie rekurencyjnych sieci neuronowych (RNN) i mechanizmów uwagi (attention) do tłumaczenia maszynowego, generowania tekstu czy analizy uczuć.
\item Rozpoznawanie mowy: zastosowanie sieci neuronowych do rozpoznawania mowy i konwersji mowy na tekst.
\item Wzmocnienie ucznia: wykorzystanie uczenia głębokiego w połączeniu z algorytmami uczenia przez wzmacnianie do sterowania robotami, pojazdami autonomicznymi czy strategiami giełdowymi.
\end{itemize}

\subsection{Różnice między uczeniem głębokim a innymi technikami uczenia maszynowego}
Uczenie głębokie różni się od innych technik uczenia maszynowego w kilku kluczowych aspektach:

\begin{itemize}
\item \textbf{Reprezentacja danych:} Uczenie głębokie automatycznie uczy się reprezentacji danych na różnych poziomach abstrakcji, podczas gdy w tradycyjnych metodach uczenia maszynowego, takich jak SVM czy drzewa decyzyjne, inżynierowie muszą ręcznie projektować cechy (feature engineering), które mają być użyte do uczenia modelu.
\item \textbf{Architektura sieci:} Sieci neuronowe stosowane w uczeniu głębokim mają wiele warstw ukrytych, co pozwala na uczenie się bardziej złożonych funkcji. W przeciwnym razie, metody uczenia maszynowego często korzystają z modeli o mniejszej złożoności, takich jak regresja liniowa czy drzewa decyzyjne.
\item \textbf{Skalowalność:} Dzięki efektywnym algorytmom optymalizacji oraz rosnącej mocy obliczeniowej, uczenie głębokie może być stosowane do przetwarzania ogromnych zbiorów danych. W porównaniu, inne techniki uczenia maszynowego mają trudności z działaniem na dużą skalę, szczególnie gdy wymagane jest ekstrahowanie cech z dużych zbiorów danych.
\item \textbf{Transfer wiedzy:} W uczeniu głębokim istnieje możliwość wykorzystania wiedzy uzyskanej z jednego zadania do innych zadań, co jest nazywane uczeniem transferowym (transfer learning). W tradycyjnym uczeniu maszynowym transfer wiedzy jest trudniejszy do osiągnięcia.
\end{itemize}

\section{Sieci konwolucyjne}
Sieci konwolucyjne (CNN) to specjalny rodzaj sieci neuronowych, w których zastosowano warstwy konwolucyjne. Warstwy te analizują obrazy za pomocą filtrów, które są przesuwane po danych wejściowych, generując mapy cech. Filtry te uczą się wykrywać lokalne wzorce, takie jak krawędzie, tekstury czy kształty. Warstwy pooling (agregujące) są stosowane w celu zmniejszenia wymiarowości map cech, co prowadzi do redukcji ilości parametrów w sieci. Sieci konwolucyjne mogą być również wykorzystywane w połączeniu z innymi warstwami, takimi jak warstwy gęsto połączone (fully connected) czy rekurencyjne (RNN), w zależności od problemu, który mają rozwiązać. Sieci neuronowe konwolucyjne funkcjonują przez gromadzenie i przetwarzanie dużych zbiorów danych w postaci siatek, a następnie ekstrakcję kluczowych cech szczegółowych w celu klasyfikacji i rozpoznawania. CNN zazwyczaj składają się z trzech głównych typów warstw: konwolucyjnej, buforowej (pooling) i w pełni połączonej. Każda z tych warstw pełni inną funkcję, wykonuje określone zadanie na zebranych danych oraz uczy się coraz bardziej złożonych aspektów.

\subsection{Jak opracowywane są sieci CNN?}
Sieci neuronowe konwolucyjne (CNN) odgrywają kluczową rolę w uczeniu głębokim i umożliwiają szerokie zastosowania w różnorodnych sektorach na całym świecie. Aby w pełni zrozumieć ich znaczenie, ważne jest, aby zrozumieć sposób ich tworzenia. Tworzenie CNN to czasochłonny i skomplikowany proces, który obejmuje trzy etapy: uczenie, optymalizację oraz wnioskowanie. Intel współpracuje bezpośrednio z programistami i analitykami danych w celu opracowania innowacyjnych metod poprawy i przyspieszenia tego procesu, co pozwala na szybsze i łatwiejsze wdrażanie nowych rozwiązań.
\subsubsection{Szkolenia}
Szkolenie (trening) w konwolucyjnych sieciach neuronowych (CNN) to proces, w którym sieć uczy się rozpoznawać wzorce i cechy na podstawie danych treningowych. Celem tego procesu jest optymalizacja wag sieci neuronowej, tak aby była w stanie dokonywać poprawnych predykcji na nowych, wcześniej niewidzianych danych. Proces szkolenia CNN składa się z kilku kroków:
\begin{itemize}
    \item \textbf{Inicjalizacja wag:} Na początek, wagi sieci neuronowej są inicjalizowane losowo lub za pomocą specjalnych technik inicjalizacji.
    \item \textbf{Przekazanie danych do sieci (propagacja wprzód):} Dane treningowe, takie jak obrazy, są przekazywane przez sieć neuronową. W trakcie tego procesu dane przechodzą przez różne warstwy sieci, takie jak warstwy konwolucyjne, warstwy buforowe (pooling) oraz warstwy w pełni połączone. W każdej warstwie sieć ekstrahuje cechy z danych wejściowych, które są przekazywane do kolejnych warstw.
    \item \textbf{Obliczenie funkcji straty:} Na końcu sieci neuronowej obliczana jest wartość funkcji straty, która mierzy różnicę między predykcjami sieci a rzeczywistymi etykietami danych treningowych. Funkcja straty jest kluczowym elementem procesu uczenia, ponieważ określa, jak dobrze sieć radzi sobie z zadaniem.
    \item \textbf{Propagacja wsteczna (Backpropagation): }Po obliczeniu funkcji straty, gradienty tej funkcji są obliczane wstecznie dla każdej warstwy sieci. Gradienty te informują o kierunku, w którym wagi sieci powinny zostać zaktualizowane, aby zmniejszyć wartość funkcji straty.
    \item \textbf{Aktualizacja wag:} Wagi sieci neuronowej są aktualizowane za pomocą algorytmu optymalizacji, takiego jak stochastyczny spadek gradientu (SGD), Adam czy RMSprop. Algorytm optymalizacji stosuje obliczone gradienty do wag sieci, modyfikując je w taki sposób, aby funkcja straty była mniejsza.
    \item \textbf{Iteracje i epoki: }Powyższe kroki są powtarzane wielokrotnie dla całego zbioru danych treningowych. Przejście przez cały zbiór danych to jedna epoka. Proces szkolenia zwykle obejmuje wiele epok, aż sieć osiągnie zadowalający poziom dokładności.
\end{itemize}
Po zakończeniu procesu szkolenia, CNN jest gotowa do przeprowadzania wnioskowania na nowych danych. Wagi sieci zostały zoptymalizowane, dzięki czemu potrafi ona dokonywać poprawnych predykcji na podstawie cech wykrytych w danych wejściowych.
\subsubsection{Optymalizacja}
Optymalizacja w konwolucyjnych sieciach neuronowych (CNN) polega na dostosowywaniu parametrów sieci w celu zminimalizowania funkcji kosztu i poprawy wydajności sieci. Proces optymalizacji prowadzi do lepszego uczenia się przez sieć istotnych cech danych wejściowych, co przekłada się na lepsze wyniki predykcji.
Optymalizacja w sieciach CNN obejmuje kilka aspektów:
\begin{itemize}
    \item \textbf{Aktualizacja wag:} Optymalizacja polega na dostosowywaniu wag sieci neuronowej w odpowiedzi na błędy popełniane podczas procesu uczenia. Metody aktualizacji wag, takie jak stochastyczny gradient prosty (SGD) czy adaptacyjne metody optymalizacji (np. Adam, RMSprop), wykorzystują informacje o gradientach funkcji kosztu do aktualizacji wag.
    \item \textbf{Dobór hiperparametrów:} Optymalizacja może obejmować dobór odpowiednich hiperparametrów, takich jak liczba warstw, liczba neuronów w każdej warstwie, współczynnik uczenia się, wielkość batcha czy funkcje aktywacji. Hiperparametry można dobrać za pomocą technik takich jak przeszukiwanie siatki, przeszukiwanie losowe czy optymalizacja bayesowska.
    \item \textbf{Regularyzacja:} Wprowadzenie technik regularyzacji, takich jak L1, L2 czy dropout, może pomóc w zapobieganiu nadmiernemu dopasowaniu sieci, co pozytywnie wpływa na jej zdolność generalizacji.
    \item \textbf{Architektura sieci:} Optymalizacja obejmuje również eksperymentowanie z różnymi architekturami sieci, aby znaleźć taką, która najlepiej radzi sobie z konkretnym zadaniem. Warto zbadać istniejące architektury, które odniosły sukces w podobnych problemach, takie jak VGG, ResNet czy Inception.
    \item \textbf{Techniki augmentacji danych:} Optymalizacja może również obejmować zastosowanie technik augmentacji danych, które polegają na wprowadzeniu różnych transformacji na danych wejściowych, takich jak obracanie, przeskalowanie, odbicie lustrzane czy zmiana oświetlenia. Augmentacja danych pomaga sieci lepiej generalizować na nowych danych.
\end{itemize}
\subsubsection{Wnioskowanie}
Wnioskowanie (ang. inference) w konwolucyjnych sieciach neuronowych (CNN) odnosi się do procesu, w którym wcześniej wytrenowana sieć jest stosowana do analizy nowych danych wejściowych i generowania predykcji. W przypadku CNN, wnioskowanie często dotyczy zastosowań takich jak klasyfikacja obrazów, detekcja obiektów czy segmentacja semantyczna.
W procesie wnioskowania, dane wejściowe, takie jak obraz, są przekazywane przez sieć CNN, która przeprowadza szereg operacji w różnych warstwach. Warstwy te obejmują warstwy konwolucyjne, warstwy buforowe (pooling) oraz warstwy w pełni połączone. Każda warstwa analizuje dane wejściowe i ekstrahuje istotne cechy, które są przekazywane do kolejnych warstw sieci.
W trakcie wnioskowania sieć neuronowa korzysta z wcześniej nauczonej hierarchii cech oraz wag, które zostały optymalizowane podczas procesu treningu. Dzięki tym wagom sieć jest w stanie rozpoznać i klasyfikować nowe dane wejściowe.
Na końcu sieci znajduje się warstwa wyjściowa, która generuje wynik końcowy, czyli predykcję. W przypadku klasyfikacji obrazów może to być prawdopodobieństwo przynależności obrazu do danej klasy. W detekcji obiektów sieć może generować współrzędne prostokątów otaczających obiekty oraz ich kategorie.
Wnioskowanie jest zwykle znacznie szybsze niż proces uczenia, ponieważ nie wymaga obliczania gradientów ani aktualizacji wag. Jako że wagi są już wcześniej nauczone, sieć koncentruje się na przeprowadzeniu operacji na nowych danych wejściowych, aby wygenerować predykcję. W przypadku aplikacji w czasie rzeczywistym, takich jak rozpoznawanie mowy czy analiza wideo, szybkość wnioskowania jest kluczowym czynnikiem wpływającym na użyteczność i skuteczność sieci neuronowej.
\section{Wady produkcyjne i ich rodzaje}
Wady produkcyjne to niezgodności w produkcji, które powodują, że produkt nie spełnia swoich wymagań jakościowych. Mogą być spowodowane przez wiele czynników, takich jak nieprawidłowości w procesie produkcyjnym, zużycie maszyn czy błędy ludzkie. Wady produkcyjne można podzielić na różne rodzaje, w zależności od charakterystyki produktu i procesu produkcyjnego. Niektóre z najbardziej powszechnych rodzajów wad produkcyjnych obejmują:

\begin{itemize}
\item \textbf{Wady powierzchniowe:} Pęknięcia, zadrapania, zmarszczki, przebarwienia czy zanieczyszczenia na powierzchni produktu.
\item \textbf{Wady geometryczne:} Niewłaściwe wymiary, kształty czy położenie elementów w stosunku do siebie nawzajem.
\item \textbf{Wady materiałowe:} Wady w strukturze materiału, takie jak pęcherze powietrza, porowatość czy zanieczyszczenia.
\item \textbf{Wady funkcjonalne:} Problemy z działaniem produktu wynikające z nieprawidłowego montażu, błędów w projektowaniu czy wadliwych komponentów.
\end{itemize}

\section{Istniejące rozwiązania}
W przemyśle istnieje wiele rozwiązań do wykrywania wad produkcyjnych. Tradycyjne metody obejmują wizualne sprawdzanie produktów przez operatorów, które może być czasochłonne i podatne na błędy. Inne metody obejmują stosowanie systemów wizyjnych z kamerami i algorytmami przetwarzania obrazów, które analizują produkty pod kątem wad. Te metody jednak często wymagają ręcznego projektowania cech oraz są trudne do skalowania.

Uczenie głębokie, a w szczególności sieci konwolucyjne, oferuje nowe możliwości w zakresie wykrywania wad produkcyjnych. Dzięki automatycznemu uczeniu się reprezentacji danych, sieci konwolucyjne potrafią wykrywać wady na obrazach z wysoką precyzją i są łatwe do skalowania. Ponadto, uczenie transferowe pozwala na zastosowanie wiedzy uzyskanej z jednego zadania do innego, co ułatwia adaptację modeli do różnych rodzajów wad i procesów produkcyjnych.

\section{Wybrane języki programowania}
\subsubsection{Python}
Python to popularny język programowania o otwartym kodzie źródłowym, który cechuje się prostotą, czytelnością i wszechstronnością. Jest szeroko stosowany w uczeniu maszynowym i uczeniu głębokim dzięki bogatemu ekosystemowi bibliotek, takich jak TensorFlow, PyTorch czy scikit-learn. Python oferuje wiele narzędzi do analizy danych, wizualizacji, pracy z obrazami i dźwię
