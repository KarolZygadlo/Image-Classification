{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4879a31-a14f-4df3-8d2a-e1b053beb673",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Instalacja oraz konfiguracja podstawowych paczek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158368ba-87e3-469c-a6de-40e2e5805c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (23.3.3)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.54.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "Collecting jax>=0.3.15\n",
      "  Using cached jax-0.4.8-py3-none-any.whl\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (16.0.0)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib64/python3.11/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib64/python3.11/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib64/python3.11/site-packages (from tensorflow) (0.32.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib64/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib64/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Collecting ml-dtypes>=0.0.3\n",
      "  Using cached ml_dtypes-0.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (190 kB)\n",
      "Collecting scipy>=1.7\n",
      "  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.1 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./.venv/lib64/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.venv/lib64/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorflow-estimator, tensorboard-data-server, pyparsing, pyasn1, protobuf, pillow, oauthlib, numpy, MarkupSafe, markdown, kiwisolver, keras, idna, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, cachetools, astunparse, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, opt-einsum, opencv-python, ml-dtypes, h5py, contourpy, requests-oauthlib, matplotlib, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.0 h5py-3.8.0 idna-3.4 jax-0.4.8 keras-2.12.0 kiwisolver-1.4.4 markdown-3.4.3 matplotlib-3.7.1 ml-dtypes-0.1.0 numpy-1.23.5 oauthlib-3.2.2 opencv-python-4.7.0.72 opt-einsum-3.3.0 pillow-9.5.0 protobuf-4.22.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pyparsing-3.0.9 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 scipy-1.10.1 tensorboard-2.12.2 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 werkzeug-2.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb9af187-8b6e-4a24-8961-218c7b4c506f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ---------\n",
      "absl-py                      1.4.0\n",
      "asttokens                    2.2.1\n",
      "astunparse                   1.6.3\n",
      "backcall                     0.2.0\n",
      "cachetools                   5.3.0\n",
      "certifi                      2022.12.7\n",
      "charset-normalizer           3.1.0\n",
      "comm                         0.1.3\n",
      "contourpy                    1.0.7\n",
      "cycler                       0.11.0\n",
      "debugpy                      1.6.7\n",
      "decorator                    5.1.1\n",
      "executing                    1.2.0\n",
      "flatbuffers                  23.3.3\n",
      "fonttools                    4.39.3\n",
      "gast                         0.4.0\n",
      "google-auth                  2.17.3\n",
      "google-auth-oauthlib         1.0.0\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.54.0\n",
      "h5py                         3.8.0\n",
      "idna                         3.4\n",
      "ipykernel                    6.22.0\n",
      "ipython                      8.12.0\n",
      "jax                          0.4.8\n",
      "jedi                         0.18.2\n",
      "jupyter_client               8.2.0\n",
      "jupyter_core                 5.3.0\n",
      "keras                        2.12.0\n",
      "kiwisolver                   1.4.4\n",
      "libclang                     16.0.0\n",
      "Markdown                     3.4.3\n",
      "MarkupSafe                   2.1.2\n",
      "matplotlib                   3.7.1\n",
      "matplotlib-inline            0.1.6\n",
      "ml-dtypes                    0.1.0\n",
      "nest-asyncio                 1.5.6\n",
      "numpy                        1.23.5\n",
      "oauthlib                     3.2.2\n",
      "opencv-python                4.7.0.72\n",
      "opt-einsum                   3.3.0\n",
      "packaging                    23.1\n",
      "parso                        0.8.3\n",
      "pexpect                      4.8.0\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.5.0\n",
      "pip                          22.3.1\n",
      "platformdirs                 3.2.0\n",
      "prompt-toolkit               3.0.38\n",
      "protobuf                     4.22.3\n",
      "psutil                       5.9.5\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.5.0\n",
      "pyasn1-modules               0.3.0\n",
      "Pygments                     2.15.1\n",
      "pyparsing                    3.0.9\n",
      "python-dateutil              2.8.2\n",
      "python-version               0.0.2\n",
      "pyzmq                        25.0.2\n",
      "requests                     2.28.2\n",
      "requests-oauthlib            1.3.1\n",
      "rsa                          4.9\n",
      "scipy                        1.10.1\n",
      "setuptools                   65.5.1\n",
      "six                          1.16.0\n",
      "stack-data                   0.6.2\n",
      "tensorboard                  2.12.2\n",
      "tensorboard-data-server      0.7.0\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.12.0\n",
      "tensorflow-estimator         2.12.0\n",
      "tensorflow-io-gcs-filesystem 0.32.0\n",
      "termcolor                    2.3.0\n",
      "tornado                      6.3.1\n",
      "traitlets                    5.9.0\n",
      "typing_extensions            4.5.0\n",
      "urllib3                      1.26.15\n",
      "wcwidth                      0.2.6\n",
      "Werkzeug                     2.2.3\n",
      "wheel                        0.40.0\n",
      "wrapt                        1.14.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc866f9a-2227-47fb-a76a-31ea7dc41256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:57:15.929143: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-24 20:57:15.930380: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 20:57:15.953648: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-24 20:57:15.954071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 20:57:16.412249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d030cd0-c8a6-498a-8645-f517e8b2cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 20:57:20.467369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-24 20:57:20.467623: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Poniższy kod zapobiega  przydzielaniu przez tensorflow całości pamięci GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1991763-4935-4897-b6da-ac3399e34752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f214ff5-e865-41b9-acad-a5ec66512e14",
   "metadata": {},
   "source": [
    "# 2. Weryfikacja, kontrola oraz usunięcie z badania uszkodzonych, wadliwych zdjęć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce65ba70-11c3-4381-82f8-e5c9f8848a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22835/4232469594.py:2: DeprecationWarning: 'imghdr' is deprecated and slated for removal in Python 3.13\n",
      "  import imghdr\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e7b761-8cb7-4c69-9e5d-0487c8bf18a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a938d33e-f9e6-4077-b683-33f5dcd4c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg', 'jpg', 'bmp', 'png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f19acb75-e4b4-4a58-b728-9b13c0f47d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_class in os.listdir(data_dir):\n",
    "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
    "        image_path = os.path.join(data_dir, image_class, image)\n",
    "        try:\n",
    "            img = cv2.imread(image_path) #sprawdzam czy mogę załadować zdjęcie do biblioteki opencv\n",
    "            tip = imghdr.what(image_path) #sprwadzam czy rozsrzeszenie zdjęcia pokrywa się z akceptowalnymi rozszerzeniami\n",
    "            if tip not in image_exts:\n",
    "                print('Zdjęcie posiada nieobsługiwane rozszerzenie {}'.format(image_path))\n",
    "                os.remove(image_path)\n",
    "        except Exception as e: \n",
    "            print('Wystąpił problem ze zdjęciem {}'.format(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630dbffa-e191-42a9-9ad0-245025df63db",
   "metadata": {},
   "source": [
    "# 3. Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951e873-0fec-4895-9ccd-d45f87e68e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce20c2c4-7e14-4723-8d43-b43506785fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data') #wywołanie zwróci zestaw danych z wskazanego katalogu, ujednolici, zmniejszy zdjęcia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd69e71-f65b-4461-ba62-f4ca054640d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator() #konwersja elementów zestawów danych na iterator, pozwoli nam uzyskać dostęp do poszczególnych danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c67737-0d9a-4997-9cca-30652059882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next() #dostęp do zestawu danych, pobranie pierwszej iteracji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc4aa0d-5b72-42b0-b6ed-047b2c7d6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for idx, img in enumerate(batch[0][:4]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803a249-f87c-4537-947e-4688c1a66aed",
   "metadata": {},
   "source": [
    "# 4. Wstępne przetwarzanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f71671e-6b34-4646-b34f-2818e24dc309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# przeskalowanie danych, w celu optymalizacji\n",
    "data = data.map(lambda x,y: (x/255, y)) # funkcja .map umożliwia operacje na całym zestawie danych\n",
    "data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4770671-6fb5-4d41-8423-e2f64b420438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7) # część zestawu danych, która będzie odpowiedzalna za trenowanie modelu\n",
    "val_size = int(len(data)*.2)+1 # część zestwu danych odpowiedzialna za walidacje\n",
    "test_size = int(len(data)*.1)+1 # część zestawu danych odpowiedzialna za końcowe testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee86fa2-bfa0-4b70-9c34-ff1c52e9e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354bcdd-da1a-491f-8d91-0c944d446cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1d0d3-cafd-4645-9e4e-59e3fd84e64a",
   "metadata": {},
   "source": [
    "# 5. Budowa modelu głębokiego uczenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dac391-462d-4eb7-9f4f-11944950e754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af9f3f-2756-461f-a717-824eae22d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7033c0a9-9712-4289-af46-0425eae14c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f1399-b6bc-4080-b0ca-912693feb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f60be-743b-4da2-8d45-68951af37f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faa9ca9-07d1-46fc-8823-43290dcc5347",
   "metadata": {},
   "source": [
    "# 6. Trenowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3499b1e-7caf-4cc2-bfd1-f1f12c66f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca48e4-21de-45c6-9e89-2536da8e4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60de975-5c99-4093-9035-5d16a8e5706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=5, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a44d7d8-a038-4e7b-a506-48bb9be14e1f",
   "metadata": {},
   "source": [
    "# 7. Badanie wydajności, wykaz strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d818e0-2ced-408c-9188-d2ee90bf1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='strata treningowa')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='strata walidacji')\n",
    "fig.suptitle('Strata', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750cba1e-319c-4be0-bb2e-a73f0483880b",
   "metadata": {},
   "source": [
    "# 8. Badanie wydajności, wykaz dokładności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc797cd5-5d2a-4961-8ebb-7194729a8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='dokładność treningowa')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='dokładność walidacji')\n",
    "fig.suptitle('Dokładność', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c050034-6a75-4a56-bbc2-29c2933afd6e",
   "metadata": {},
   "source": [
    "# 9. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b4eef-ec6a-4224-ad3e-200d2ee862c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('testing/failure_4.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeae0f6-aad6-4a68-b7a3-4c272c2ae790",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f83e3-11db-49b3-ad6f-90cb9eea04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat  = model.predict(np.expand_dims(resize/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8cc21-af0f-4f2d-8ff2-ffd6b6863d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b4ac6-4be3-4656-a5d4-f1bd5027cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if yhat > 0.5:\n",
    "    print(f'Wskazany obraz został sklasyfikowany jako część prawidłowa')\n",
    "else:\n",
    "    print(f'Wskazany obraz został sklasyfikowany jako część uszkodzona')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc2a954d-7739-442f-bace-08b00d88de3d",
   "metadata": {},
   "source": [
    "# 10. Zapis modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0c8ef-9012-4af2-90a3-3e23e23dbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13f27a-b599-4bbd-9f3f-a0e3c9dad6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('models', 'imageclassicationversionlive.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9f913-e23e-42d8-a4a5-9ffce0468f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models', 'imageclassicationversionlive.h5'))\n",
    "\n",
    "img = cv2.imread('testing/failure_4.png')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "resize = tf.image.resize(img, (256,256))\n",
    "plt.imshow(resize.numpy().astype(int))\n",
    "plt.show()\n",
    "\n",
    "yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "if yhat > 0.5:\n",
    "    print(f'Wskazany obraz został sklasyfikowany jako część prawidłowa')\n",
    "else:\n",
    "    print(f'Wskazany obraz został sklasyfikowany jako część uszkodzona')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c64797c0",
   "metadata": {},
   "source": [
    "# 11. Ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0147e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = load_model(os.path.join('models', 'imageclassicationversionlive.h5'))\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ewaluacja modelu na zbiorze testowym\n",
    "y_test = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in test:\n",
    "    predictions = model.predict(images)\n",
    "    predictions = np.round(predictions).reshape(-1)\n",
    "    y_test.extend(labels.numpy())\n",
    "    y_pred.extend(predictions)\n",
    "\n",
    "# Obliczenie precyzji, czułości (recall) i F1-score\n",
    "report = classification_report(y_test, y_pred, target_names=['uszkodzony', 'prawidłowy'], output_dict=True)\n",
    "print(report)\n",
    "\n",
    "# Wizualizacja raportu klasyfikacji\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df = report_df[:-3]  # Usunięcie zbędnych wierszy (accuracy, macro avg, weighted avg)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=report_df.index, y='f1-score', data=report_df)\n",
    "plt.ylim(0, 1)\n",
    "plt.title('F1-score dla poszczególnych klas')\n",
    "plt.xlabel('Klasy')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
